{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:28: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from ssd import SSD300\n",
    "from ssd_training import MultiboxLoss\n",
    "from ssd_utils import BBoxUtility\n",
    "from data_utils import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some constants\n",
    "INPUT_WIDTH = 300\n",
    "INPUT_HEIGHT = 300 \n",
    "NUM_CLASSES = 8 + 1 # 1 because of background (needed for training)\n",
    "DATA_PATH = '/a/data/fisheries_monitoring/data/'\n",
    "\n",
    "input_shape = (INPUT_HEIGHT, INPUT_WIDTH, 3)\n",
    "classes = ['ALB', 'DOL', 'NoF', 'SHARK', 'BET', 'LAG', 'OTHER', 'YFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "priors = pickle.load(open('prior_boxes_ssd300.pkl', 'rb'))\n",
    "bbox_util = BBoxUtility(NUM_CLASSES, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 \tfolder name: /a/data/fisheries_monitoring/data/localizers/splice\n",
      "index: 1 \tfolder name: /a/data/fisheries_monitoring/data/localizers/invert\n",
      "index: 2 \tfolder name: /a/data/fisheries_monitoring/data/localizers/vflip\n",
      "index: 3 \tfolder name: /a/data/fisheries_monitoring/data/localizers/add\n",
      "index: 4 \tfolder name: /a/data/fisheries_monitoring/data/localizers/emboss\n",
      "index: 5 \tfolder name: /a/data/fisheries_monitoring/data/localizers/gaussianNoise\n",
      "index: 6 \tfolder name: /a/data/fisheries_monitoring/data/localizers/blur\n",
      "index: 7 \tfolder name: /a/data/fisheries_monitoring/data/localizers/original\n",
      "index: 8 \tfolder name: /a/data/fisheries_monitoring/data/localizers/dropout\n",
      "index: 9 \tfolder name: /a/data/fisheries_monitoring/data/localizers/rotate\n"
     ]
    }
   ],
   "source": [
    "aug_folders = glob.glob(DATA_PATH + 'localizers/*')\n",
    "for i, folder in enumerate(aug_folders):\n",
    "    print \"index:\", i, '\\t', \"folder name:\", folder\n",
    "    \n",
    "aug_folders = aug_folders[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batch_size, bbox_util, boxes, classes, INPUT_WIDTH, INPUT_HEIGHT):\n",
    "    while True:\n",
    "        #img_batch = np.zeros((batch_size, INPUT_HEIGHT, INPUT_WIDTH, 3))\n",
    "        #box_batch = np.zeros((batch_size, 4))\n",
    "        img_batch = []\n",
    "        target_batch = []\n",
    "        for file_name, value in boxes.iteritems():\n",
    "            print file_name\n",
    "            # Obtain label for that file (remember file path in pattern aug_type/label/frame.png)\n",
    "            label = file_name.split('/')[1]\n",
    "            # Then create a one-hot encoding vector for the classes\n",
    "            label_vector = [1 if i == label else 0 for i in classes]\n",
    "\n",
    "            # Read img and preprocess it\n",
    "            path = DATA_PATH + 'localizers/' + file_name\n",
    "            img = image.load_img(path)\n",
    "                \n",
    "            width, height = img.size\n",
    "            img = img.resize((INPUT_HEIGHT, INPUT_WIDTH))\n",
    "            img = image.img_to_array(img)\n",
    "            img /= 255\n",
    "            img_batch.append(img)\n",
    "            print value\n",
    "            #target = bbox_util.assign_boxes(target)\n",
    "            old_x, old_y, old_w, old_h, id = value\n",
    "            new_x = old_x / width\n",
    "            new_y = old_y / height\n",
    "            new_w = old_w / width\n",
    "            new_h = old_h / height\n",
    "            \n",
    "            target = [new_x, new_y, new_x + new_w, new_y + new_h] + label_vector\n",
    "            target = bbox_util.assign_boxes(np.array(target)[np.newaxis, :])\n",
    "            \n",
    "            target_batch.append(target)\n",
    "            \n",
    "            if len(target_batch) == batch_size:\n",
    "                tmp_img_batch = np.array(img_batch)\n",
    "                tmp_target_batch = np.array(target_batch)\n",
    "                img_batch = []\n",
    "                target_batch = []\n",
    "                yield (tmp_img_batch, tmp_target_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data augmentation folder: invert\n",
      "Number of examples: 8740\n",
      "\n",
      "Loading data augmentation folder: vflip\n",
      "Number of examples: 17480\n",
      "\n",
      "Loading data augmentation folder: add\n",
      "Number of examples: 8740\n",
      "\n",
      "Loading data augmentation folder: emboss\n",
      "Number of examples: 4370\n",
      "\n",
      "Loading data augmentation folder: gaussianNoise\n",
      "Number of examples: 13110\n",
      "\n",
      "Loading data augmentation folder: blur\n",
      "Number of examples: 8740\n",
      "\n",
      "Loading data augmentation folder: original\n",
      "Number of examples: 4370\n",
      "\n",
      "Loading data augmentation folder: dropout\n",
      "Number of examples: 8740\n",
      "\n",
      "Loading data augmentation folder: rotate\n",
      "Number of examples: 30582\n",
      "\n",
      "total number of examples:  104872\n"
     ]
    }
   ],
   "source": [
    "#gt = pickle.load(open('gt_pascal.pkl', 'rb'))\n",
    "#keys = sorted(gt.keys())\n",
    "#num_train = int(round(0.8 * len(keys)))\n",
    "#train_keys = keys[:num_train]\n",
    "#val_keys = keys[num_train:]\n",
    "#num_val = len(val_keys)\n",
    "\n",
    "aug_labels, og_labels = load_all_labels(aug_folders, 'boxes_with_id.csv')\n",
    "train_labels, val_labels = train_val_split(aug_labels, og_labels, 0.7, 0.3)\n",
    "\n",
    "train_labels = train_labels.set_index('img').T.to_dict('list')\n",
    "val_labels = val_labels.set_index('img').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "train_steps = np.ceil(len(train_labels)/batch_size)\n",
    "\n",
    "gen = data_generator(batch_size, bbox_util, train_labels, classes, INPUT_HEIGHT, INPUT_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ssd.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv1_1\")`\n",
      "  name='conv1_1')(net['input'])\n",
      "ssd.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv1_2\")`\n",
      "  name='conv1_2')(net['conv1_1'])\n",
      "ssd.py:46: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool1\")`\n",
      "  name='pool1')(net['conv1_2'])\n",
      "ssd.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv2_1\")`\n",
      "  name='conv2_1')(net['pool1'])\n",
      "ssd.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv2_2\")`\n",
      "  name='conv2_2')(net['conv2_1'])\n",
      "ssd.py:57: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool2\")`\n",
      "  name='pool2')(net['conv2_2'])\n",
      "ssd.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv3_1\")`\n",
      "  name='conv3_1')(net['pool2'])\n",
      "ssd.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv3_2\")`\n",
      "  name='conv3_2')(net['conv3_1'])\n",
      "ssd.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv3_3\")`\n",
      "  name='conv3_3')(net['conv3_2'])\n",
      "ssd.py:72: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool3\")`\n",
      "  name='pool3')(net['conv3_3'])\n",
      "ssd.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv4_1\")`\n",
      "  name='conv4_1')(net['pool3'])\n",
      "ssd.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv4_2\")`\n",
      "  name='conv4_2')(net['conv4_1'])\n",
      "ssd.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv4_3\")`\n",
      "  name='conv4_3')(net['conv4_2'])\n",
      "ssd.py:87: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool4\")`\n",
      "  name='pool4')(net['conv4_3'])\n",
      "ssd.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv5_1\")`\n",
      "  name='conv5_1')(net['pool4'])\n",
      "ssd.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv5_2\")`\n",
      "  name='conv5_2')(net['conv5_1'])\n",
      "ssd.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv5_3\")`\n",
      "  name='conv5_3')(net['conv5_2'])\n",
      "ssd.py:102: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), padding=\"same\", strides=(1, 1), name=\"pool5\")`\n",
      "  name='pool5')(net['conv5_3'])\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.py:757: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n",
      "  warnings.warn('The `AtrousConvolution2D` layer '\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.py:761: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), padding=\"same\", activation=\"relu\", dilation_rate=(6, 6), name=\"fc6\")`\n",
      "  return Conv2D(*args, **kwargs)\n",
      "ssd.py:110: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), padding=\"same\", activation=\"relu\", name=\"fc7\")`\n",
      "  border_mode='same', name='fc7')(net['fc6'])\n",
      "ssd.py:115: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), padding=\"same\", activation=\"relu\", name=\"conv6_1\")`\n",
      "  name='conv6_1')(net['fc7'])\n",
      "ssd.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", strides=(2, 2), activation=\"relu\", name=\"conv6_2\")`\n",
      "  name='conv6_2')(net['conv6_1'])\n",
      "ssd.py:122: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), padding=\"same\", activation=\"relu\", name=\"conv7_1\")`\n",
      "  name='conv7_1')(net['conv6_2'])\n",
      "ssd.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"valid\", strides=(2, 2), activation=\"relu\", name=\"conv7_2\")`\n",
      "  name='conv7_2')(net['conv7_2'])\n",
      "ssd.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), padding=\"same\", activation=\"relu\", name=\"conv8_1\")`\n",
      "  name='conv8_1')(net['conv7_2'])\n",
      "ssd.py:133: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", strides=(2, 2), activation=\"relu\", name=\"conv8_2\")`\n",
      "  name='conv8_2')(net['conv8_1'])\n",
      "ssd.py:140: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), padding=\"same\", name=\"conv4_3_norm_mbox_loc\")`\n",
      "  name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n",
      "ssd.py:148: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(27, (3, 3), padding=\"same\", name=\"conv4_3_norm_mbox_conf_9\")`\n",
      "  name=name)(net['conv4_3_norm'])\n",
      "ssd.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"fc7_mbox_loc\")`\n",
      "  name='fc7_mbox_loc')(net['fc7'])\n",
      "ssd.py:168: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(54, (3, 3), padding=\"same\", name=\"fc7_mbox_conf_9\")`\n",
      "  name=name)(net['fc7'])\n",
      "ssd.py:178: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"conv6_2_mbox_loc\")`\n",
      "  name='conv6_2_mbox_loc')(net['conv6_2'])\n",
      "ssd.py:186: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(54, (3, 3), padding=\"same\", name=\"conv6_2_mbox_conf_9\")`\n",
      "  name=name)(net['conv6_2'])\n",
      "ssd.py:197: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"conv7_2_mbox_loc\")`\n",
      "  name='conv7_2_mbox_loc')(net['conv7_2'])\n",
      "ssd.py:205: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(54, (3, 3), padding=\"same\", name=\"conv7_2_mbox_conf_9\")`\n",
      "  name=name)(net['conv7_2'])\n",
      "ssd.py:216: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"conv8_2_mbox_loc\")`\n",
      "  name='conv8_2_mbox_loc')(net['conv8_2'])\n",
      "ssd.py:224: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(54, (3, 3), padding=\"same\", name=\"conv8_2_mbox_conf_9\")`\n",
      "  name=name)(net['conv8_2'])\n",
      "ssd.py:258: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1, name='mbox_loc')\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "ssd.py:265: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1, name='mbox_conf')\n",
      "ssd.py:273: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='mbox_priorbox')\n",
      "ssd.py:288: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='predictions')\n"
     ]
    }
   ],
   "source": [
    "model = SSD300(input_shape, num_classes=NUM_CLASSES)\n",
    "model.load_weights(DATA_PATH + 'models/localizers/weights_SSD300.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freeze = ['input_1', 'conv1_1', 'conv1_2', 'pool1',\n",
    "          'conv2_1', 'conv2_2', 'pool2',\n",
    "          'conv3_1', 'conv3_2', 'conv3_3', 'pool3']#,\n",
    "#           'conv4_1', 'conv4_2', 'conv4_3', 'pool4']\n",
    "\n",
    "for L in model.layers:\n",
    "    if L.name in freeze:\n",
    "        L.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(epoch, decay=0.9):\n",
    "    return base_lr * decay**(epoch)\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint('./checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                                             verbose=1,\n",
    "                                             save_weights_only=True),\n",
    "             keras.callbacks.LearningRateScheduler(schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_lr = 3e-4\n",
    "optim = keras.optimizers.Adam(lr=base_lr)\n",
    "# optim = keras.optimizers.RMSprop(lr=base_lr)\n",
    "# optim = keras.optimizers.SGD(lr=base_lr, momentum=0.9, decay=decay, nesterov=True)\n",
    "model.compile(optimizer=optim,\n",
    "              loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f8ae303905e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                               nb_worker=1)\n\u001b[0m",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1557\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1943\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 30\n",
    "val_gen = data_generator(batch_size, bbox_util, val_labels, classes, INPUT_WIDTH, INPUT_HEIGHT)\n",
    "val_steps = np.ceil(len(val_labels)/batch_size)\n",
    "\n",
    "history = model.fit_generator(gen, len(train_labels),\n",
    "                              nb_epoch, verbose=2,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_gen,\n",
    "                              nb_val_samples=len(val_labels),\n",
    "                              nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "images = []\n",
    "img_path = path_prefix + sorted(val_keys)[0]\n",
    "img = image.load_img(img_path, target_size=(300, 300))\n",
    "img = image.img_to_array(img)\n",
    "images.append(imread(img_path))\n",
    "inputs.append(img.copy())\n",
    "inputs = preprocess_input(np.array(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "results = bbox_util.detection_out(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(images):\n",
    "    # Parse the outputs.\n",
    "    det_label = results[i][:, 0]\n",
    "    det_conf = results[i][:, 1]\n",
    "    det_xmin = results[i][:, 2]\n",
    "    det_ymin = results[i][:, 3]\n",
    "    det_xmax = results[i][:, 4]\n",
    "    det_ymax = results[i][:, 5]\n",
    "\n",
    "    # Get detections with confidence higher than 0.6.\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.6]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n",
    "\n",
    "    plt.imshow(img / 255.)\n",
    "    currentAxis = plt.gca()\n",
    "\n",
    "    for i in range(top_conf.shape[0]):\n",
    "        xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "        ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "        xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "        ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "        score = top_conf[i]\n",
    "        label = int(top_label_indices[i])\n",
    "#         label_name = voc_classes[label - 1]\n",
    "        display_txt = '{:0.2f}, {}'.format(score, label)\n",
    "        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "        color = colors[label]\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:28: UserWarning: [Errno 13] Permission denied.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from random import shuffle\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from ssd import SSD300\n",
    "from ssd_training import MultiboxLoss\n",
    "from ssd_utils import BBoxUtility\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some constants\n",
    "INPUT_WIDTH = 300\n",
    "INPUT_HEIGHT = 300 \n",
    "NUM_CLASSES = 8\n",
    "DATA_PATH = '/a/data/fisheries_monitoring/data/'\n",
    "\n",
    "input_shape = (INPUT_HEIGHT, INPUT_WIDTH, 3)\n",
    "classes = ['ALB', 'DOL', 'NoF', 'SHARK', 'BET', 'LAG', 'OTHER', 'YFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priors = pickle.load(open('prior_boxes_ssd300.pkl', 'rb'))\n",
    "bbox_util = BBoxUtility(NUM_CLASSES, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 \tfolder name: /a/data/fisheries_monitoring/data/localizers/splice\n",
      "index: 1 \tfolder name: /a/data/fisheries_monitoring/data/localizers/invert\n",
      "index: 2 \tfolder name: /a/data/fisheries_monitoring/data/localizers/vflip\n",
      "index: 3 \tfolder name: /a/data/fisheries_monitoring/data/localizers/add\n",
      "index: 4 \tfolder name: /a/data/fisheries_monitoring/data/localizers/emboss\n",
      "index: 5 \tfolder name: /a/data/fisheries_monitoring/data/localizers/gaussianNoise\n",
      "index: 6 \tfolder name: /a/data/fisheries_monitoring/data/localizers/blur\n",
      "index: 7 \tfolder name: /a/data/fisheries_monitoring/data/localizers/original\n",
      "index: 8 \tfolder name: /a/data/fisheries_monitoring/data/localizers/dropout\n",
      "index: 9 \tfolder name: /a/data/fisheries_monitoring/data/localizers/rotate\n",
      "['/a/data/fisheries_monitoring/data/localizers/invert', '/a/data/fisheries_monitoring/data/localizers/vflip', '/a/data/fisheries_monitoring/data/localizers/add', '/a/data/fisheries_monitoring/data/localizers/emboss', '/a/data/fisheries_monitoring/data/localizers/gaussianNoise', '/a/data/fisheries_monitoring/data/localizers/blur', '/a/data/fisheries_monitoring/data/localizers/original', '/a/data/fisheries_monitoring/data/localizers/dropout', '/a/data/fisheries_monitoring/data/localizers/rotate']\n"
     ]
    }
   ],
   "source": [
    "aug_folders = glob.glob(DATA_PATH + 'localizers/*')\n",
    "for i, folder in enumerate(aug_folders):\n",
    "    print \"index:\", i, '\\t', \"folder name:\", folder\n",
    "    \n",
    "aug_folders = aug_folders[1:]\n",
    "\n",
    "print aug_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batch_size, boxes, classes, INPUT_WIDTH, INPUT_HEIGHT):\n",
    "    # Shuffle labels to ensure \n",
    "    labels = shuffle(boxes)\n",
    "    while True:\n",
    "        #img_batch = np.zeros((batch_size, INPUT_HEIGHT, INPUT_WIDTH, 3))\n",
    "        #box_batch = np.zeros((batch_size, 4))\n",
    "        img_batch = []\n",
    "        target_batch = []\n",
    "        for index, row in boxes.iterrows():\n",
    "            # Get next file to read\n",
    "            file_name = row[\"img\"]\n",
    "            \n",
    "            # Obtain label for that file (remember file path in pattern aug_type/label/frame.png)\n",
    "            label = file_name.split('/')[1]\n",
    "            # Then create a one-hot encoding vector for the classes\n",
    "            label_vector = [1 if i == label else 0 for i in classes]\n",
    "\n",
    "            # Read img and preprocess it\n",
    "            path = DATA_PATH + 'localizers/' + file_name\n",
    "            img = image.load_img(path)\n",
    "            width, height = img.size\n",
    "            img = img.resize((INPUT_HEIGHT, INPUT_WIDTH))\n",
    "            img = image.img_to_array(img)\n",
    "            img /= 255\n",
    "            img_batch.append(img)\n",
    "            \n",
    "            # Read box and normalize its measures\n",
    "            old_x, old_y, old_w, old_h = row[[\"x\",\"y\",\"w\",\"h\"]]\n",
    "            new_x = old_x / width\n",
    "            new_y = old_y / height\n",
    "            new_w = old_w / width\n",
    "            new_h = old_h / height\n",
    "            \n",
    "            target = [new_x, new_y, new_x + new_w, new_y + new_h] + label_vector\n",
    "            target_batch.append(target)\n",
    "            \n",
    "            if len(target_batch) == batch_size:\n",
    "                yield (img_batch, target_batch)\n",
    "                \n",
    "        \n",
    "def load_all_labels(aug_folders):\n",
    "    all_labels = pd.DataFrame(columns = [\"img\", \"x\",\"y\",\"w\",\"h\"])\n",
    "    for folder in aug_folders:\n",
    "        folder_name = os.path.basename(folder)\n",
    "        \n",
    "        print \"Loading data augmentation folder:\", folder_name\n",
    "        targets = pd.read_csv(folder + '/superboxes.csv', names = [\"img\", \"x\",\"y\",\"w\",\"h\"])\n",
    "        targets = labels.sort_values(by = \"img\")\n",
    "        targets[\"img\"] = folder_name + '/' + targets[\"img\"]\n",
    "        print \"Number of examples:\", len(targets)\n",
    "        print\n",
    "        \n",
    "        all_targets = all_targets.append(targets)\n",
    "    print \"total number of examples: \", len(all_targets)\n",
    "    return all_targets\n",
    "\n",
    "\n",
    "def train_val_test_split(all_labels, val_size, test_size):\n",
    "    all_labels = shuffle(all_labels)\n",
    "    test_labels = all_labels[0:test_size]\n",
    "    val_labels = all_labels[test_size:test_size + val_size]\n",
    "    train_labels = all_labels[test_size + val_size:]\n",
    "    return train_labels, val_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data augmentation folder: invert\n",
      "Number of examples: 6620\n",
      "\n",
      "Loading data augmentation folder: vflip\n",
      "Number of examples: 13240\n",
      "\n",
      "Loading data augmentation folder: add\n",
      "Number of examples: 6620\n",
      "\n",
      "Loading data augmentation folder: emboss\n",
      "Number of examples: 3310\n",
      "\n",
      "Loading data augmentation folder: gaussianNoise\n",
      "Number of examples: 9930\n",
      "\n",
      "Loading data augmentation folder: blur\n",
      "Number of examples: 6620\n",
      "\n",
      "Loading data augmentation folder: original\n",
      "Number of examples: 3310\n",
      "\n",
      "Loading data augmentation folder: dropout\n",
      "Number of examples: 6620\n",
      "\n",
      "Loading data augmentation folder: rotate\n",
      "Number of examples: 23170\n",
      "\n",
      "total number of examples:  79440\n"
     ]
    }
   ],
   "source": [
    "#gt = pickle.load(open('gt_pascal.pkl', 'rb'))\n",
    "#keys = sorted(gt.keys())\n",
    "#num_train = int(round(0.8 * len(keys)))\n",
    "#train_keys = keys[:num_train]\n",
    "#val_keys = keys[num_train:]\n",
    "#num_val = len(val_keys)\n",
    "\n",
    "all_labels = load_all_labels(aug_folders)\n",
    "\n",
    "train_labels, val_labels, test_labels = train_val_test_split(all_labels, 2000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "train_steps = np.ceil(len(train_labels)/batch_size)\n",
    "\n",
    "gen = data_generator(batch_size, train_labels, classes, INPUT_HEIGHT, INPUT_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ssd.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv1_1\")`\n",
      "  name='conv1_1')(net['input'])\n",
      "ssd.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv1_2\")`\n",
      "  name='conv1_2')(net['conv1_1'])\n",
      "ssd.py:46: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool1\")`\n",
      "  name='pool1')(net['conv1_2'])\n",
      "ssd.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv2_1\")`\n",
      "  name='conv2_1')(net['pool1'])\n",
      "ssd.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv2_2\")`\n",
      "  name='conv2_2')(net['conv2_1'])\n",
      "ssd.py:57: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool2\")`\n",
      "  name='pool2')(net['conv2_2'])\n",
      "ssd.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv3_1\")`\n",
      "  name='conv3_1')(net['pool2'])\n",
      "ssd.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv3_2\")`\n",
      "  name='conv3_2')(net['conv3_1'])\n",
      "ssd.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv3_3\")`\n",
      "  name='conv3_3')(net['conv3_2'])\n",
      "ssd.py:72: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool3\")`\n",
      "  name='pool3')(net['conv3_3'])\n",
      "ssd.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv4_1\")`\n",
      "  name='conv4_1')(net['pool3'])\n",
      "ssd.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv4_2\")`\n",
      "  name='conv4_2')(net['conv4_1'])\n",
      "ssd.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv4_3\")`\n",
      "  name='conv4_3')(net['conv4_2'])\n",
      "ssd.py:87: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), padding=\"same\", strides=(2, 2), name=\"pool4\")`\n",
      "  name='pool4')(net['conv4_3'])\n",
      "ssd.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv5_1\")`\n",
      "  name='conv5_1')(net['pool4'])\n",
      "ssd.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv5_2\")`\n",
      "  name='conv5_2')(net['conv5_1'])\n",
      "ssd.py:100: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv5_3\")`\n",
      "  name='conv5_3')(net['conv5_2'])\n",
      "ssd.py:102: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), padding=\"same\", strides=(1, 1), name=\"pool5\")`\n",
      "  name='pool5')(net['conv5_3'])\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.py:753: UserWarning: The `AtrousConvolution2D` layer  has been deprecated. Use instead the `Conv2D` layer with the `dilation_rate` argument.\n",
      "  warnings.warn('The `AtrousConvolution2D` layer '\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.py:757: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), padding=\"same\", activation=\"relu\", dilation_rate=(6, 6), name=\"fc6\")`\n",
      "  return Conv2D(*args, **kwargs)\n",
      "ssd.py:110: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), padding=\"same\", activation=\"relu\", name=\"fc7\")`\n",
      "  border_mode='same', name='fc7')(net['fc6'])\n",
      "ssd.py:115: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), padding=\"same\", activation=\"relu\", name=\"conv6_1\")`\n",
      "  name='conv6_1')(net['fc7'])\n",
      "ssd.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", strides=(2, 2), activation=\"relu\", name=\"conv6_2\")`\n",
      "  name='conv6_2')(net['conv6_1'])\n",
      "ssd.py:122: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), padding=\"same\", activation=\"relu\", name=\"conv7_1\")`\n",
      "  name='conv7_1')(net['conv6_2'])\n",
      "ssd.py:126: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"valid\", strides=(2, 2), activation=\"relu\", name=\"conv7_2\")`\n",
      "  name='conv7_2')(net['conv7_2'])\n",
      "ssd.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), padding=\"same\", activation=\"relu\", name=\"conv8_1\")`\n",
      "  name='conv8_1')(net['conv7_2'])\n",
      "ssd.py:133: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", strides=(2, 2), activation=\"relu\", name=\"conv8_2\")`\n",
      "  name='conv8_2')(net['conv8_1'])\n",
      "ssd.py:140: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), padding=\"same\", name=\"conv4_3_norm_mbox_loc\")`\n",
      "  name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n",
      "ssd.py:148: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"conv4_3_norm_mbox_conf_8\")`\n",
      "  name=name)(net['conv4_3_norm'])\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/engine/topology.py:559: UserWarning: Class `ssd_layers.PriorBox` defines `get_output_shape_for` but does not override `compute_output_shape`. If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.\n",
      "  output_shape = self.compute_output_shape(input_shape)\n",
      "ssd.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"fc7_mbox_loc\")`\n",
      "  name='fc7_mbox_loc')(net['fc7'])\n",
      "ssd.py:168: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), padding=\"same\", name=\"fc7_mbox_conf_8\")`\n",
      "  name=name)(net['fc7'])\n",
      "ssd.py:178: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"conv6_2_mbox_loc\")`\n",
      "  name='conv6_2_mbox_loc')(net['conv6_2'])\n",
      "ssd.py:186: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), padding=\"same\", name=\"conv6_2_mbox_conf_8\")`\n",
      "  name=name)(net['conv6_2'])\n",
      "ssd.py:197: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"conv7_2_mbox_loc\")`\n",
      "  name='conv7_2_mbox_loc')(net['conv7_2'])\n",
      "ssd.py:205: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), padding=\"same\", name=\"conv7_2_mbox_conf_8\")`\n",
      "  name=name)(net['conv7_2'])\n",
      "ssd.py:216: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), padding=\"same\", name=\"conv8_2_mbox_loc\")`\n",
      "  name='conv8_2_mbox_loc')(net['conv8_2'])\n",
      "ssd.py:224: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (3, 3), padding=\"same\", name=\"conv8_2_mbox_conf_8\")`\n",
      "  name=name)(net['conv8_2'])\n",
      "ssd.py:258: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1, name='mbox_loc')\n",
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "ssd.py:265: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  mode='concat', concat_axis=1, name='mbox_conf')\n",
      "ssd.py:273: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='mbox_priorbox')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\"concat\" mode can only merge layers with matching output shapes except for the concat axis. Layer shapes: [(None, 38, 38, 512), (None, 19, 19, 1024), (None, 10, 10, 512), (None, 5, 5, 256), (None, 3, 3, 256), (None, 1, 1, 256)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-95ded2f566a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSSD300\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'models/localizers/weights_SSD300.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/comp150dl/fisheries_monitoring/localizers/SSD/ssd.py\u001b[0m in \u001b[0;36mSSD300\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m    271\u001b[0m                                   net['pool6_mbox_priorbox']],\n\u001b[0;32m    272\u001b[0m                                  \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'concat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m                                  name='mbox_priorbox')\n\u001b[0m\u001b[0;32m    274\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mbox_loc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mnum_boxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mbox_loc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.pyc\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(inputs, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, name)\u001b[0m\n\u001b[0;32m    454\u001b[0m                             \u001b[0mnode_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                             \u001b[0mtensor_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m                             name=name)\n\u001b[0m\u001b[0;32m    457\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmerge_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, node_indices, tensor_indices, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m             self._arguments_validation(layers, mode,\n\u001b[0;32m    106\u001b[0m                                        \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdot_axes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                                        node_indices, tensor_indices)\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/layers.pyc\u001b[0m in \u001b[0;36m_arguments_validation\u001b[1;34m(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)\u001b[0m\n\u001b[0;32m    185\u001b[0m                                  \u001b[1;34m'layers with matching '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                                  \u001b[1;34m'output shapes except for the concat axis. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m                                  'Layer shapes: %s' % (input_shapes))\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \"concat\" mode can only merge layers with matching output shapes except for the concat axis. Layer shapes: [(None, 38, 38, 512), (None, 19, 19, 1024), (None, 10, 10, 512), (None, 5, 5, 256), (None, 3, 3, 256), (None, 1, 1, 256)]"
     ]
    }
   ],
   "source": [
    "model = SSD300(input_shape, num_classes=NUM_CLASSES)\n",
    "model.load_weights(DATA_PATH + 'models/localizers/weights_SSD300.hdf5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-01c88a5f2a13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#           'conv4_1', 'conv4_2', 'conv4_3', 'pool4']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mL\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfreeze\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "freeze = ['input_1', 'conv1_1', 'conv1_2', 'pool1',\n",
    "          'conv2_1', 'conv2_2', 'pool2',\n",
    "          'conv3_1', 'conv3_2', 'conv3_3', 'pool3']#,\n",
    "#           'conv4_1', 'conv4_2', 'conv4_3', 'pool4']\n",
    "\n",
    "for L in model.layers:\n",
    "    if L.name in freeze:\n",
    "        L.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def schedule(epoch, decay=0.9):\n",
    "    return base_lr * decay**(epoch)\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint('./checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                                             verbose=1,\n",
    "                                             save_weights_only=True),\n",
    "             keras.callbacks.LearningRateScheduler(schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_lr = 3e-4\n",
    "optim = keras.optimizers.Adam(lr=base_lr)\n",
    "# optim = keras.optimizers.RMSprop(lr=base_lr)\n",
    "# optim = keras.optimizers.SGD(lr=base_lr, momentum=0.9, decay=decay, nesterov=True)\n",
    "model.compile(optimizer=optim,\n",
    "              loss=MultiboxLoss(NUM_CLASSES, neg_pos_ratio=2.0).compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 2548.0, 30, verbose=1, workers=1, validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=66.0)`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (30, 4) for Tensor u'predictions_target_1:0', which has shape '(?, ?, ?)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-123d0a734a5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                               nb_worker=1)\n\u001b[0m",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1876\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1878\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1621\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2073\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/a/h/jsendi01/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    942\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    945\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (30, 4) for Tensor u'predictions_target_1:0', which has shape '(?, ?, ?)'"
     ]
    }
   ],
   "source": [
    "nb_epoch = 30\n",
    "val_gen = data_generator(batch_size, val_labels, INPUT_WIDTH, INPUT_HEIGHT)\n",
    "val_steps = np.ceil(len(val_labels)/batch_size)\n",
    "\n",
    "history = model.fit_generator(gen, train_steps,\n",
    "                              nb_epoch, verbose=1,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_steps,\n",
    "                              nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "images = []\n",
    "img_path = path_prefix + sorted(val_keys)[0]\n",
    "img = image.load_img(img_path, target_size=(300, 300))\n",
    "img = image.img_to_array(img)\n",
    "images.append(imread(img_path))\n",
    "inputs.append(img.copy())\n",
    "inputs = preprocess_input(np.array(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = model.predict(inputs, batch_size=1, verbose=1)\n",
    "results = bbox_util.detection_out(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, img in enumerate(images):\n",
    "    # Parse the outputs.\n",
    "    det_label = results[i][:, 0]\n",
    "    det_conf = results[i][:, 1]\n",
    "    det_xmin = results[i][:, 2]\n",
    "    det_ymin = results[i][:, 3]\n",
    "    det_xmax = results[i][:, 4]\n",
    "    det_ymax = results[i][:, 5]\n",
    "\n",
    "    # Get detections with confidence higher than 0.6.\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= 0.6]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 4)).tolist()\n",
    "\n",
    "    plt.imshow(img / 255.)\n",
    "    currentAxis = plt.gca()\n",
    "\n",
    "    for i in range(top_conf.shape[0]):\n",
    "        xmin = int(round(top_xmin[i] * img.shape[1]))\n",
    "        ymin = int(round(top_ymin[i] * img.shape[0]))\n",
    "        xmax = int(round(top_xmax[i] * img.shape[1]))\n",
    "        ymax = int(round(top_ymax[i] * img.shape[0]))\n",
    "        score = top_conf[i]\n",
    "        label = int(top_label_indices[i])\n",
    "#         label_name = voc_classes[label - 1]\n",
    "        display_txt = '{:0.2f}, {}'.format(score, label)\n",
    "        coords = (xmin, ymin), xmax-xmin+1, ymax-ymin+1\n",
    "        color = colors[label]\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "        currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
